{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ku8IZ0HSVTl9"
      },
      "outputs": [],
      "source": [
        "import tifffile as tiff\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy import nan\n",
        "#from patchify import patchify\n",
        "#from DataGenerater import batch_generator\n",
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
        "\n",
        "from tensorflow import keras\n",
        "import segmentation_models as sm\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, cohen_kappa_score\n",
        "from sklearn.impute import KNNImputer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attention 3D U-net"
      ],
      "metadata": {
        "id": "XXriu6SHVvc8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Input, Conv3D, MaxPooling3D, UpSampling3D, concatenate, BatchNormalization, Activation,add,Add,Conv3DTranspose,multiply,Reshape,Conv2D,Dropout\n",
        "\n",
        "\n",
        "def attention_block(x, g, inter_channel):\n",
        "    theta_x = Conv3D(inter_channel, [1, 1, 1], strides=[1, 1, 1])(x)\n",
        "\n",
        "    phi_g = Conv3D(inter_channel, [1, 1, 1], strides=[1, 1, 1])(g)\n",
        "\n",
        "    f = Activation('relu')(add([theta_x, phi_g]))\n",
        "\n",
        "    psi_f = Conv3D(1, [1, 1, 1], strides=[1, 1, 1])(f)\n",
        "\n",
        "    rate = Activation('sigmoid')(psi_f)\n",
        "\n",
        "    att_x = multiply([x, rate])\n",
        "\n",
        "    return att_x\n",
        "\n",
        "def conv_block(tensor, nfilters, size=3, padding='same', initializer=\"he_normal\"):\n",
        "    x = Conv3D(filters=nfilters, kernel_size=(size, size, size), padding=padding, kernel_initializer=initializer)(tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Conv3D(filters=nfilters*2, kernel_size=(size, size, size), padding=padding, kernel_initializer=initializer)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    return x\n",
        "\n",
        "def conv_block2(tensor, nfilters, size=3, padding='same', initializer=\"he_normal\"):\n",
        "    x = Conv3D(filters=nfilters/2, kernel_size=(size, size, size), padding=padding, kernel_initializer=initializer)(tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Conv3D(filters=nfilters/2, kernel_size=(size, size, size), padding=padding, kernel_initializer=initializer)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    return x\n",
        "\n",
        "def deconv_block(tensor, residual, nfilters, size=2, strides=2, padding='same', initializer=\"he_normal\"):\n",
        "    #y = UpSampling3D(size=(size, size, size))(tensor)\n",
        "    y = Conv3DTranspose(filters= nfilters, kernel_size= (size, size,1), strides=(strides, strides,1), padding=padding)(tensor)\n",
        "    #y = Conv3D(filters=nfilters, kernel_size=(size, size, size), strides=(strides, strides, strides), padding=padding, kernel_initializer=initializer)(y)\n",
        "    y = attention_block(y, residual, nfilters)\n",
        "    y = Dropout(0.5)(y)\n",
        "    y = concatenate([y, residual])\n",
        "    y = conv_block2(y, nfilters)\n",
        "    return y\n",
        "\n",
        "def AttentionUnet_3D(input_shape1,input_shape2,input_shape3, nfilters=16, initializer=\"he_normal\"):\n",
        "    # Base\n",
        "    inputs = Input(input_shape1)\n",
        "    reshaped_inputs = Reshape((input_shape1[0], input_shape1[1], 4, 3))(inputs)\n",
        "\n",
        "    # Downsampling\n",
        "    conv1 = conv_block(reshaped_inputs, nfilters)\n",
        "    pool1 = MaxPooling3D(pool_size=(2, 2, 1),strides=(2,2,1))(conv1)\n",
        "\n",
        "    conv2 = conv_block(pool1, nfilters*2)\n",
        "    pool2 = MaxPooling3D(pool_size=(2, 2, 1),strides=(2,2,1))(conv2)\n",
        "\n",
        "    conv3 = conv_block(pool2, nfilters*4) #### 128\n",
        "    pool3 = MaxPooling3D(pool_size=(2, 2, 1),strides=(2,2,1))(conv3)\n",
        "\n",
        "    conv4 = conv_block(pool3, nfilters*8) ###  256\n",
        "    print(conv4.shape)\n",
        "    print(conv3.shape)\n",
        "\n",
        "    # Upsampling\n",
        "    deconv3 = deconv_block(conv4, conv3, nfilters*16)\n",
        "\n",
        "    deconv2 = deconv_block(deconv3, conv2, nfilters*8)\n",
        "\n",
        "    deconv1 = deconv_block(deconv2, conv1, nfilters*4)\n",
        "\n",
        "\n",
        "    ##################################################################################################\n",
        "\n",
        "    inputs2 = Input(input_shape2)\n",
        "    reshaped_inputs2 = Reshape((input_shape2[0], input_shape2[1], 10, 2))(inputs2)\n",
        "\n",
        "    # Downsampling\n",
        "    conv11 = conv_block(reshaped_inputs2, nfilters)\n",
        "    pool11 = MaxPooling3D(pool_size=(2, 2, 1),strides=(2,2,1))(conv11)\n",
        "\n",
        "    conv22 = conv_block(pool11, nfilters*2)\n",
        "    pool22 = MaxPooling3D(pool_size=(2, 2, 1),strides=(2,2,1))(conv22)\n",
        "\n",
        "    conv33 = conv_block(pool22, nfilters*4)\n",
        "    pool33 = MaxPooling3D(pool_size=(2, 2, 1),strides=(2,2,1))(conv33)\n",
        "\n",
        "    conv44 = conv_block(pool33, nfilters*8)\n",
        "    print(conv44.shape)\n",
        "    print(conv33.shape)\n",
        "\n",
        "    # Upsampling\n",
        "    deconv33 = deconv_block(conv44, conv33, nfilters*16)\n",
        "\n",
        "    deconv22 = deconv_block(deconv33, conv22, nfilters*8)\n",
        "\n",
        "    deconv11 = deconv_block(deconv22, conv11, nfilters*4)\n",
        "\n",
        "    #deconv33 = MaxPooling3D(pool_size=(1, 1, 2),strides=(1,1,2))(deconv33)\n",
        "    #deconv22 = MaxPooling3D(pool_size=(1, 1, 2),strides=(1,1,2))(deconv22)\n",
        "    #deconv11 = MaxPooling3D(pool_size=(1, 1, 2),strides=(1,1,2))(deconv11)\n",
        "\n",
        "  ###############################################################################\n",
        "    inputs3 = Input(input_shape3)\n",
        "    reshaped_inputs3 = Reshape((input_shape2[0], input_shape2[1], 10, 2))(inputs3)\n",
        "\n",
        "    # Downsampling\n",
        "    conv111 = conv_block(reshaped_inputs3, nfilters)\n",
        "    pool111 = MaxPooling3D(pool_size=(2, 2, 1),strides=(2,2,1))(conv111)\n",
        "\n",
        "    conv222 = conv_block(pool111, nfilters*2)\n",
        "    pool222 = MaxPooling3D(pool_size=(2, 2, 1),strides=(2,2,1))(conv222)\n",
        "\n",
        "    conv333 = conv_block(pool222, nfilters*4)\n",
        "    pool333 = MaxPooling3D(pool_size=(2, 2, 1),strides=(2,2,1))(conv333)\n",
        "\n",
        "    conv444 = conv_block(pool333, nfilters*8)\n",
        "    print(conv444.shape)\n",
        "    print(conv333.shape)\n",
        "\n",
        "    # Upsampling\n",
        "    deconv333 = deconv_block(conv444, conv333, nfilters*16)\n",
        "\n",
        "    deconv222 = deconv_block(deconv333, conv222, nfilters*8)\n",
        "\n",
        "    deconv111 = deconv_block(deconv222, conv111, nfilters*4)\n",
        "\n",
        "    #deconv33 = MaxPooling3D(pool_size=(1, 1, 5),strides=(1,1,5))(deconv33)\n",
        "    #deconv22 = MaxPooling3D(pool_size=(1, 1, 5),strides=(1,1,5))(deconv22)\n",
        "    #deconv11 = MaxPooling3D(pool_size=(1, 1, 5),strides=(1,1,5))(deconv11)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    ##########################################################################\n",
        "\n",
        "    feature_map3 = concatenate([deconv3, deconv33,deconv333],axis=3)\n",
        "    print(feature_map3.shape)\n",
        "    up3 = UpSampling3D(size=(2, 2, 1))(feature_map3)\n",
        "    print(up3.shape)\n",
        "    up3 = Conv3D(64, (1, 1,1))(up3)\n",
        "    print(up3.shape)\n",
        "\n",
        "    feature_map2 = concatenate([deconv2, deconv22,deconv222],axis=3)\n",
        "    print(feature_map2.shape)\n",
        "\n",
        "    add_feature_map = Add()([up3,feature_map2])\n",
        "\n",
        "\n",
        "    feature_map1 = concatenate([deconv1, deconv11,deconv111],axis=3)\n",
        "    print(feature_map1.shape)\n",
        "\n",
        "    up2 = UpSampling3D(size=(2, 2, 1))(add_feature_map)\n",
        "    up2 = Conv3D(32, (1, 1,1))(up2)\n",
        "\n",
        "    add_feature_map = Add()([up2,feature_map1])\n",
        "    print(add_feature_map.shape)\n",
        "\n",
        "\n",
        "    # Output\n",
        "    output1 = Conv3D(filters=32, kernel_size=(1, 1, 3), padding='valid',activation='relu')(add_feature_map)\n",
        "    output1 = MaxPooling3D(pool_size=(1, 1, 2),strides=(1,1,2))(output1)\n",
        "    output1 = Conv3D(filters=16, kernel_size=(1, 1, 3), padding='valid',activation='relu')(output1)\n",
        "    output1 = MaxPooling3D(pool_size=(1, 1, 2),strides=(1,1,2))(output1)\n",
        "\n",
        "    x= Reshape((128, 128, 64))(output1)\n",
        "    output2 = Conv2D(5, (1,1), activation='softmax')(x)\n",
        "\n",
        "    model = Model([inputs,inputs2,inputs3], output2)\n",
        "\n",
        "    return model\n",
        "\n",
        "input_shape1 = (128, 128, 12)# Adjust based on your input\n",
        "input_shape2 = (128, 128, 20)\n",
        "input_shape3 = (128, 128, 20)\n",
        "\n",
        "model = AttentionUnet_3D(input_shape1,input_shape2,input_shape3)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "byjj9tkjV264"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer based on three sources"
      ],
      "metadata": {
        "id": "I9a0qaneZItb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer\n",
        "\n",
        "class PositionalEncoding(Layer):\n",
        "    def __init__(self, d_model, pe_tau, max_seq_len=5000, **kwargs):\n",
        "        super(PositionalEncoding, self).__init__(**kwargs)\n",
        "        self.d_model = d_model\n",
        "        self.pe_tau = pe_tau\n",
        "        self.max_seq_len = max_seq_len\n",
        "\n",
        "        # Compute the positional encoding matrix\n",
        "        pe = np.zeros((max_seq_len, d_model))\n",
        "        position = np.arange(0, max_seq_len)[:, np.newaxis].astype(np.float32)\n",
        "        divisor = -np.exp(\n",
        "            np.arange(0, d_model, 2).astype(np.float32)\n",
        "            * np.log(pe_tau) / d_model\n",
        "        )\n",
        "        pe[:, 0::2] = np.sin(position * divisor)\n",
        "        pe[:, 1::2] = np.cos(position * divisor)\n",
        "\n",
        "        # Expand dimensions for batch size compatibility\n",
        "        self.pe = tf.constant(pe[:, np.newaxis, :], dtype=tf.float32)\n",
        "\n",
        "    def call(self, x):\n",
        "        batch_size = tf.shape(x)[0]\n",
        "        seq_len = tf.shape(x)[1]\n",
        "        return x + self.pe[:batch_size, :seq_len, :]\n"
      ],
      "metadata": {
        "id": "NT8-lLXwV29W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, Dropout, Activation,GlobalAveragePooling1D,Flatten,Reshape,Input,Dense\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "\n",
        "def TransformerClassifier(input_shape, d_model, nhead, dim_feedforward, dropout, num_layers, num_classes, pe_tau):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = Dense(d_model)(inputs)\n",
        "    x = PositionalEncoding(d_model, pe_tau)(x)\n",
        "    print(x.shape)\n",
        "\n",
        "    # Transformer blocks\n",
        "    for _ in range(num_layers):\n",
        "        # Multi-head attention and normalization\n",
        "        query = x\n",
        "        key = x\n",
        "        value = x\n",
        "        attn_output = MultiHeadAttention(num_heads=nhead, key_dim=d_model)(query, value, key)\n",
        "        attn_output = Dropout(dropout)(attn_output)\n",
        "        out1 = LayerNormalization(epsilon=1e-6)(attn_output + x)\n",
        "\n",
        "        # Feed-forward neural network and normalization\n",
        "        ffn_output = Dense(dim_feedforward, activation=\"relu\")(out1)\n",
        "        ffn_output = Dense(d_model)(ffn_output)\n",
        "        ffn_output = Dropout(dropout)(ffn_output)\n",
        "        x = LayerNormalization(epsilon=1e-6)(ffn_output + out1)\n",
        "\n",
        "    x = GlobalAveragePooling1D(data_format='channels_last')(x)\n",
        "    #outputs = x\n",
        "\n",
        "    outputs = Dense(d_model, activation='relu')(x)\n",
        "    return Model(inputs=inputs, outputs=outputs)"
      ],
      "metadata": {
        "id": "CpHrJZ_qXVyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# three sources\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "def MultiInputModel(input_shapes, d_model, nhead, dim_feedforward, dropout, num_layers, num_classes, pe_tau):\n",
        "    inputs1 = Input(shape=input_shapes[0])\n",
        "    inputs2 = Input(shape=input_shapes[1])\n",
        "    inputs3 = Input(shape=input_shapes[2])\n",
        "\n",
        "    model1 = TransformerClassifier(input_shapes[0], d_model, nhead, dim_feedforward, dropout, num_layers, num_classes, pe_tau)\n",
        "    model2 = TransformerClassifier(input_shapes[1], d_model, nhead, dim_feedforward, dropout, num_layers, num_classes, pe_tau)\n",
        "    model3 = TransformerClassifier(input_shapes[2], d_model, nhead, dim_feedforward, dropout, num_layers, num_classes, pe_tau)\n",
        "\n",
        "    out1 = model1(inputs1)\n",
        "    out2 = model2(inputs2)\n",
        "    out3 = model3(inputs3)\n",
        "\n",
        "    concatenated = tf.keras.layers.concatenate([out1, out2,out3], axis=1)\n",
        "\n",
        "\n",
        "    dense_layer1 = Dense(units=512, activation='relu')(concatenated)\n",
        "    dense_layer2 = Dropout(0.5)(dense_layer1)\n",
        "    outputs = Dense(units=num_classes, activation='softmax')(concatenated)\n",
        "\n",
        "    return Model(inputs=[inputs1, inputs2,inputs3], outputs=outputs)\n",
        "\n",
        "input_shapes = [(10, 2),(10,2), (4, 3)]\n",
        "model2 = MultiInputModel(input_shapes, d_model=128, nhead=4, dim_feedforward=256, dropout=0.5, num_layers=2, num_classes=5, pe_tau=10000)\n",
        "model2.summary()"
      ],
      "metadata": {
        "id": "koP9v6Z5V2_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer-AtLSTM (Backbone)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eHRWYNtjZQMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Model\n",
        "\n",
        "def MultiInputModelWithConcatOutput(input_shapes, d_model, nhead, dim_feedforward, dropout, num_layers, num_classes, pe_tau):\n",
        "    inputs1 = Input(shape=input_shapes[0])\n",
        "    inputs2 = Input(shape=input_shapes[1])\n",
        "    inputs3 = Input(shape=input_shapes[2])\n",
        "\n",
        "    model1 = TransformerClassifier(input_shapes[0], d_model, nhead, dim_feedforward, dropout, num_layers, num_classes, pe_tau)\n",
        "    model2 = TransformerClassifier(input_shapes[1], d_model, nhead, dim_feedforward, dropout, num_layers, num_classes, pe_tau)\n",
        "    model3 = TransformerClassifier(input_shapes[2], d_model, nhead, dim_feedforward, dropout, num_layers, num_classes, pe_tau)\n",
        "\n",
        "    out1 = model1(inputs1)\n",
        "    out2 = model2(inputs2)\n",
        "    out3 = model3(inputs3)\n",
        "\n",
        "    #concatenated = tf.keras.layers.concatenate([out1, out2 ], axis=1)\n",
        "    return Model(inputs=[inputs1, inputs2, inputs3], outputs=[out1,out2,out3])"
      ],
      "metadata": {
        "id": "bxdqCYEiX7Jo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saved the weights of the pretrained model\n",
        "pretrained_weights_path = 'gdrive/My Drive/Chapter 5/transformer_tracks_2017.h5'\n",
        "\n",
        "backbone_model = MultiInputModelWithConcatOutput(input_shapes, d_model=64, nhead=4, dim_feedforward=256, dropout=0.5, num_layers=2, num_classes=5, pe_tau=10000)\n",
        "backbone_model.load_weights(pretrained_weights_path, by_name=True)"
      ],
      "metadata": {
        "id": "MFYitcvYYmyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Lambda, dot, concatenate, Dense, Dropout, Activation, Input, Bidirectional, LSTM\n",
        "import tensorflow as tf\n",
        "\n",
        "def attention_2d_block(hidden_states, name_suffix=''):\n",
        "    print(\"Shape of hidden_states:\", hidden_states.shape)  # Debug statement\n",
        "\n",
        "    hidden_size = int(hidden_states.shape[1])\n",
        "    score_first_part = Dense(hidden_size, use_bias=False, name='attention_score_vec' + name_suffix)(hidden_states)\n",
        "\n",
        "    print(\"Shape of score_first_part:\", score_first_part.shape)  # Debug statement\n",
        "\n",
        "    h_t = Lambda(lambda x: x[:, -1, :], output_shape=(hidden_size,), name='last_hidden_state' + name_suffix)(hidden_states)\n",
        "\n",
        "    print(\"Shape of h_t:\", h_t.shape)  # Debug statement\n",
        "\n",
        "    score = dot([score_first_part, h_t], [1, 1], name='attention_score' + name_suffix)\n",
        "    attention_weights = Activation('softmax', name='attention_weight' + name_suffix)(score)\n",
        "    context_vector = dot([hidden_states, attention_weights], [1, 1], name='context_vector' + name_suffix)\n",
        "    pre_activation = concatenate([context_vector, h_t], name='attention_output' + name_suffix)\n",
        "    attention_vector = Dense(256, use_bias=False, activation='tanh', name='attention_vector' + name_suffix)(pre_activation)\n",
        "    return attention_vector\n",
        "\n",
        "def model1(init, name_suffix=''):\n",
        "    x = init\n",
        "    # Expand dimensions\n",
        "    x = Lambda(lambda x: tf.expand_dims(x, axis=2), output_shape=lambda s: (s[0], s[1], 1))(x)\n",
        "    x = Bidirectional(LSTM(32, return_sequences=True))(x)\n",
        "    x = attention_2d_block(x, name_suffix)  # Pass the name_suffix here\n",
        "    out = Dense(512, activation=\"relu\")(x)\n",
        "    return out"
      ],
      "metadata": {
        "id": "1ra6V0GuYm1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for atlstm use transformer as backbone\n",
        "inputs1 = Input(shape=input_shapes[0])\n",
        "inputs2 = Input(shape=input_shapes[1])\n",
        "inputs3 = Input(shape=input_shapes[2])\n",
        "\n",
        "out1,out2,out3 = backbone_model([inputs1, inputs2, inputs3])\n",
        "\n",
        "out11 = model1(out1, '_1')\n",
        "out22 = model1(out2, '_2')\n",
        "out33 = model1(out3, '_3')\n",
        "concat_output2 = tf.keras.layers.concatenate([out11, out22, out33], axis=1)\n",
        "\n",
        "\n",
        "#concatenated2 = tf.keras.layers.concatenate([concat_output, concat_output2], axis=1)\n",
        "dense_layer1 = Dense(units=512, activation='relu')(concat_output2)\n",
        "dense_layer2 = Dropout(0.5)(dense_layer1)\n",
        "outputs = Dense(units=5, activation='softmax')(dense_layer2)\n",
        "\n",
        "\n",
        "\n",
        "new_model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs)\n",
        "new_model.summary()"
      ],
      "metadata": {
        "id": "EDzwrh5vYm3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer-AtLSTM (Ensemble)"
      ],
      "metadata": {
        "id": "X1W9eJixbC3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#attention LSTM\n",
        "\n",
        "def attention_3d_block(hidden_states, name_suffix=''):\n",
        "    # hidden_states.shape = (batch_size, time_steps, hidden_size)\n",
        "    hidden_size = int(hidden_states.shape[2])\n",
        "    # Inside dense layer\n",
        "    #              hidden_states            dot               W            =>           score_first_part\n",
        "    # (batch_size, time_steps, hidden_size) dot (hidden_size, hidden_size) => (batch_size, time_steps, hidden_size)\n",
        "    # W is the trainable weight matrix of attention\n",
        "    # Luong's multiplicative style score\n",
        "    # Modify the layer names to include the name_suffix\n",
        "    score_first_part = Dense(hidden_size, use_bias=False, name='attention_score_vec' + name_suffix)(hidden_states)\n",
        "    h_t = Lambda(lambda x: x[:, -1, :], output_shape=(hidden_size,), name='last_hidden_state' + name_suffix)(\n",
        "        hidden_states)\n",
        "    score = dot([score_first_part, h_t], [2, 1], name='attention_score' + name_suffix)\n",
        "    attention_weights = Activation('softmax', name='attention_weight' + name_suffix)(score)\n",
        "    context_vector = dot([hidden_states, attention_weights], [1, 1], name='context_vector' + name_suffix)\n",
        "    pre_activation = concatenate([context_vector, h_t], name='attention_output' + name_suffix)\n",
        "    attention_vector = Dense(256, use_bias=False, activation='softmax',\n",
        "                             name='attention_vector' + name_suffix)(\n",
        "        pre_activation)\n",
        "    return attention_vector"
      ],
      "metadata": {
        "id": "fmD8vaC_aFFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Lambda,dot,concatenate\n",
        "\n",
        "def model1(init, name_suffix=''):\n",
        "    x = init\n",
        "    x = Bidirectional(LSTM(32, return_sequences=True))(x)\n",
        "    x = attention_3d_block(x, name_suffix)  # Pass the name_suffix here\n",
        "    out = Dense(512, activation=\"relu\")(x)\n",
        "    return out"
      ],
      "metadata": {
        "id": "e5evTlLeaFIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saved the weights of the pretrained model\n",
        "pretrained_weights_path = 'gdrive/My Drive/Chapter 5/transformer_tracks_2017.h5'\n",
        "\n",
        "backbone_model = MultiInputModelWithConcatOutput(input_shapes, d_model=64, nhead=4, dim_feedforward=256, dropout=0.5, num_layers=2, num_classes=5, pe_tau=10000)\n",
        "backbone_model.load_weights(pretrained_weights_path, by_name=True)"
      ],
      "metadata": {
        "id": "GXNkNQtDbdML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformer and Atlstm ensemble learning\n",
        "inputs1 = Input(shape=input_shapes[0])\n",
        "inputs2 = Input(shape=input_shapes[1])\n",
        "inputs3 = Input(shape=input_shapes[2])\n",
        "\n",
        "concat_output = backbone_model([inputs1, inputs2, inputs3])\n",
        "\n",
        "out1 = model1(inputs1, '_1')\n",
        "out2 = model1(inputs2, '_2')\n",
        "out3 = model1(inputs3, '_3')\n",
        "concat_output2 = tf.keras.layers.concatenate([out1, out2, out3], axis=1)\n",
        "\n",
        "\n",
        "concatenated2 = tf.keras.layers.concatenate([concat_output, concat_output2], axis=1)\n",
        "dense_layer1 = Dense(units=512, activation='relu')(concatenated2)\n",
        "dense_layer2 = Dropout(0.5)(dense_layer1)\n",
        "outputs = Dense(units=5, activation='softmax')(dense_layer2)\n",
        "\n",
        "\n",
        "\n",
        "new_model2 = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
        "new_model2.summary()"
      ],
      "metadata": {
        "id": "nQmOYtIhZsE2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
